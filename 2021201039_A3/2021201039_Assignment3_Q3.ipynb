{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHUJV0vRhzDI"
      },
      "source": [
        "# Assignment 3\n",
        "\n",
        "## Instructions\n",
        "- Run this notebook on ```Google Colab(preferable)```\n",
        "- Write your code and analysis in the indicated cells.\n",
        "- Ensure that this notebook runs without errors when the cells are run in sequence.\n",
        "- Do not attempt to change the contents of other cells. \n",
        "\n",
        "## Packages Used\n",
        "- sklearn [link](https://scikit-learn.org/)\n",
        "- Keras [link](https://keras.io/guides/)\n",
        "\n",
        "## Submission\n",
        "- Rename the notebook to `<roll_number>_Assignment3_Q3.ipynb`.\n",
        "\n",
        "\n",
        "## Question 3\n",
        "Fake news is a widespread problem and there are many methods for combating it.\n",
        "You have to build a fake news detection system using a ML model. Train any ML model (ANN, LSTM) over the given Dataset.\n",
        "The dataset has short statements spoken by people and has the meta-information and corresponding label for those sentences. \n",
        "Your target is label column which has 6 labels(in the increasing order of truthfullness): pants-fire, false, barely-true, half-true, mostly-true, true.\n",
        "\n",
        "The features are 'statement', 'subject', 'speaker', 'job', 'state', 'party', 'barely_true_c', 'false_c', 'half_true_c', 'mostly_true_c', 'pants_on_fire_c', 'venue' and the target is column \"label\".\n",
        "\n",
        "The statement is made by speaker whose job, party are given along with 6 columns which are an account of the  type of news(labels) the person has shared before. \n",
        "The person who has shared fake content before is likely to share it in future and this can be accounted by the ML model as a feature. Column barely_true_c contains how many barely_true news has the speaker shared (and so is with column X_c, value of X_c is number of X the person shared).\n",
        "\n",
        "\n",
        "You have to perform two tasks:\n",
        "* task1: Binary classification <br>\n",
        "Classify the given news as true/false. Take the labels pants-fire, false, barely-true as false and rest (half-true, mostly-true, true) as true.\n",
        "* task2: Six-way classification <br>\n",
        "Classify the given news into six-classes \"pants-fire, false, barely-true, half-true, mostly-true, true\".\n",
        "\n",
        "For each of the tasks:\n",
        "1) Experiment with depth of network and try to fine-tune hyperparameters reporting your observations. <br>\n",
        "2) Report the accuracy, f1-score, confusion matrix on train, val and test sets. <br>\n",
        "3) Experiment with bag-of-words, glove and bert embeddings(code given in the below notebook) and report results. <br> Comment on what is the affect of embedding on the results.\n",
        "\n",
        "The pre-processing code is provided, you need to write the training and test.\n",
        "\n",
        "Note: You are supposed to train on trainset, fine-tune on val and just eval on test set. If found that you trained on val/test sets, the penalty will be incurred."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m14If2KThzDM"
      },
      "outputs": [],
      "source": [
        "# !pip install numpy\n",
        "# !pip install tensorflow\n",
        "# !pip install re\n",
        "# !pip install nltk\n",
        "# !pip install keras\n",
        "# !pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Agl6JEo_gaBT",
        "outputId": "90304ad9-9077-4407-f1c6-a829c0aef836"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras  #feel free to use any other library\n",
        "import numpy as np\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "nltk.download('stopwords')\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Activation\n",
        "from sklearn.metrics import multilabel_confusion_matrix,accuracy_score,f1_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VQkfcX93hzDQ"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "val = pd.read_csv('val.csv')\n",
        "test = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "enAZ4DvUffVr"
      },
      "outputs": [],
      "source": [
        "# Dropping the 'id' column\n",
        "train.drop('id', axis = 1, inplace = True)\n",
        "test.drop('id', axis = 1, inplace = True)\n",
        "val.drop('id', axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "7pEJ-G4yITrd",
        "outputId": "6f1f307c-3e8c-441a-dd97-cadf3399f99c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         label                                          statement  \\\n",
              "0        False  Says the Annies List political group supports ...   \n",
              "1    half-true  When did the decline of coal start? It started...   \n",
              "2  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
              "3        False  Health care reform legislation is likely to ma...   \n",
              "4    half-true  The economic turnaround started at the end of ...   \n",
              "\n",
              "                              subject         speaker                   job  \\\n",
              "0                            abortion    dwayne-bohac  State representative   \n",
              "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
              "2                      foreign-policy    barack-obama             President   \n",
              "3                         health-care    blog-posting                   NaN   \n",
              "4                        economy,jobs   charlie-crist                   NaN   \n",
              "\n",
              "      state       party  barely_true_c  false_c  half_true_c  mostly_true_c  \\\n",
              "0     Texas  republican              0        1            0              0   \n",
              "1  Virginia    democrat              0        0            1              1   \n",
              "2  Illinois    democrat             70       71          160            163   \n",
              "3       NaN        none              7       19            3              5   \n",
              "4   Florida    democrat             15        9           20             19   \n",
              "\n",
              "   pants_on_fire_c                venue  \n",
              "0                0             a mailer  \n",
              "1                0      a floor speech.  \n",
              "2                9               Denver  \n",
              "3               44       a news release  \n",
              "4                2  an interview on CNN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6b23702f-0d83-486a-b8e0-a752c7c1faf9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>statement</th>\n",
              "      <th>subject</th>\n",
              "      <th>speaker</th>\n",
              "      <th>job</th>\n",
              "      <th>state</th>\n",
              "      <th>party</th>\n",
              "      <th>barely_true_c</th>\n",
              "      <th>false_c</th>\n",
              "      <th>half_true_c</th>\n",
              "      <th>mostly_true_c</th>\n",
              "      <th>pants_on_fire_c</th>\n",
              "      <th>venue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>Says the Annies List political group supports ...</td>\n",
              "      <td>abortion</td>\n",
              "      <td>dwayne-bohac</td>\n",
              "      <td>State representative</td>\n",
              "      <td>Texas</td>\n",
              "      <td>republican</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a mailer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>half-true</td>\n",
              "      <td>When did the decline of coal start? It started...</td>\n",
              "      <td>energy,history,job-accomplishments</td>\n",
              "      <td>scott-surovell</td>\n",
              "      <td>State delegate</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>democrat</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>a floor speech.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mostly-true</td>\n",
              "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
              "      <td>foreign-policy</td>\n",
              "      <td>barack-obama</td>\n",
              "      <td>President</td>\n",
              "      <td>Illinois</td>\n",
              "      <td>democrat</td>\n",
              "      <td>70</td>\n",
              "      <td>71</td>\n",
              "      <td>160</td>\n",
              "      <td>163</td>\n",
              "      <td>9</td>\n",
              "      <td>Denver</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>Health care reform legislation is likely to ma...</td>\n",
              "      <td>health-care</td>\n",
              "      <td>blog-posting</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>none</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>44</td>\n",
              "      <td>a news release</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>half-true</td>\n",
              "      <td>The economic turnaround started at the end of ...</td>\n",
              "      <td>economy,jobs</td>\n",
              "      <td>charlie-crist</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Florida</td>\n",
              "      <td>democrat</td>\n",
              "      <td>15</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>an interview on CNN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b23702f-0d83-486a-b8e0-a752c7c1faf9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6b23702f-0d83-486a-b8e0-a752c7c1faf9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6b23702f-0d83-486a-b8e0-a752c7c1faf9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbFqDO8_U6df",
        "outputId": "9664dd56-472a-46dd-9811-4080f9a0cd01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10269, 13)\n",
            "(1284, 13)\n",
            "(1283, 13)\n"
          ]
        }
      ],
      "source": [
        "# Checking the shape of data\n",
        "print(train.shape)\n",
        "print(val.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXD63-vNhzDS"
      },
      "source": [
        "## Clean and pre-process data\n",
        "* Replace missing values\n",
        "* Remove numbers and special characters\n",
        "* Convert to upper-case\n",
        "\n",
        "We experiment with two types of processing, one directly appending the other attributes like subject, job, state, party to sentence and then applying bag of words on it.\n",
        "\n",
        "Other being encoding sentence with glove embeddings and passing just that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "w7tTpAClApgJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def dataPreprocessing(data):\n",
        "    '''Function for cleaning the dataset\n",
        "    '''\n",
        "    corpus = []\n",
        "    # Missing values\n",
        "    data[\"job\"].fillna(\"no-job\", inplace = True)\n",
        "    data[\"state\"].fillna(\"no-state\", inplace = True)\n",
        "\n",
        "    for x in range(data.shape[0]):\n",
        "        statement = re.sub('[^a-zA-Z]', ' ', data['statement'][x]) # Removing all numbers and special characters\n",
        "        statement = statement.lower() # Converting uppercase to lowercase\n",
        "        statement = statement.split()\n",
        "        \n",
        "        # you can experiment with any other stemmers\n",
        "        ps = PorterStemmer()\n",
        "        statement = [ps.stem(word) for word in statement if not word in set(stopwords.words('english'))] # Stemming the dataset and removing stopwords\n",
        "        statement = ' '.join(statement)\n",
        "        subject = data['subject'][x].replace(',', ' ')\n",
        "        speaker = data['speaker'][x]\n",
        "        job = data['job'][x].lower()\n",
        "        # job = job.replace(' ', '-')\n",
        "        state = data['state'][x].lower()\n",
        "        party = data['party'][x].lower()\n",
        "        corpus.append(statement + ' '  + subject + ' ' + job + ' ' + state + ' ' + party)\n",
        "    return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uy1ikPhJ9LoS"
      },
      "outputs": [],
      "source": [
        "x_train = dataPreprocessing(train)\n",
        "x_val = dataPreprocessing(val) \n",
        "x_test = dataPreprocessing(test) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM2EU_GVhzDU",
        "outputId": "cd6c5dec-f4cf-44b1-e92a-360fac2e11a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10269, 1284, 1283)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(x_train), len(x_val), len(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ysJ0qClyhzDU"
      },
      "outputs": [],
      "source": [
        "corpus = x_train + x_val + x_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCKUy35whzDV"
      },
      "source": [
        "## Using bag-of-words embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sopw2zusZwn4"
      },
      "outputs": [],
      "source": [
        "# Converting the corpus into bag-of-words\n",
        "cv = CountVectorizer(max_features = 8000)\n",
        "X = cv.fit_transform(corpus).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OkhaYt6hzDV",
        "outputId": "28124fb3-26f9-4c57-f999-d3700bbc3cdb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [1, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o06bP9FJEaMU",
        "outputId": "29010573-2b85-4093-abc1-876b8919ab79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12836, 8000)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGneZZUlhzDX",
        "outputId": "c618212a-1533-4c8b-adde-ba3a7c555e2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['label', 'statement', 'subject', 'speaker', 'job', 'state', 'party',\n",
              "       'barely_true_c', 'false_c', 'half_true_c', 'mostly_true_c',\n",
              "       'pants_on_fire_c', 'venue'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RCqMgDpiLDhu"
      },
      "outputs": [],
      "source": [
        "# Selecting the columns 'barely_true_c',\t'false_c',\t'half_true_c',\t'mostly_true_c',\t'pants_on_fire_c'\n",
        "label_cols = ['barely_true_c', 'false_c', 'half_true_c', 'mostly_true_c',\n",
        "       'pants_on_fire_c']\n",
        "x_train2 = train[label_cols]\n",
        "x_val2 = val[label_cols]\n",
        "x_test2 = test[label_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "QglKXzA_w6DH"
      },
      "outputs": [],
      "source": [
        "# Stacking x_train and x_train2 horizontally\n",
        "x_train_bow = np.hstack((X[:len(x_train)], x_train2))\n",
        "x_val_bow = np.hstack((X[len(x_train):len(x_train)+len(x_val)], x_val2))\n",
        "x_test_bow = np.hstack((X[len(x_train)+len(x_val):], x_test2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3pskgViw99U",
        "outputId": "bc311929-0234-4d75-fc5b-a4188496c16e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10269, 8005)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "x_train_bow.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1kEkGk_hzDY"
      },
      "source": [
        "## Use of Glove Embedding\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj-1LSz3hzDZ"
      },
      "source": [
        "download glove embeddings from 'https://nlp.stanford.edu/data/glove.6B.zip','glove.6B.zip'\n",
        "and place in your current working folder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNxmpIWA2Uct",
        "outputId": "22a7aa5b-8513-44d7-f4d1-c0a0368ae65b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-16 18:15:35--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-04-16 18:15:35--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-04-16 18:15:35--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1       48%[========>           ] 397.50M  5.00MB/s    eta 81s    ^C\n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syep1xuQhzDZ",
        "outputId": "b9843cff-54ff-44c3-bb55-bf924228fd6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.6B.zip\n",
            "replace glove/glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip \"glove.6B.zip\" -d \"glove\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7YNcpVFKhzDa"
      },
      "outputs": [],
      "source": [
        "emmbed_dict = {}\n",
        "with open('glove/glove.6B.200d.txt','r') as f:\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vector = np.asarray(values[1:],'float32')\n",
        "    emmbed_dict[word]=vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "jIe9ANxUhzDa"
      },
      "outputs": [],
      "source": [
        "emmbed_dict['oov'] = np.zeros(200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhXxX9Py_c-g",
        "outputId": "a43ce27d-729a-4926-edc3-55100b9b4cd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.2.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.21.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.1.96)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.4.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.11.1+cu111)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.5.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.18.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.10.0+cu111)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence_transformers) (4.1.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.0.49)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.12.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (4.11.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "RT_nyQ7NhzDa"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OY0JhmfjhzDb",
        "outputId": "e444347b-3889-48b2-cb0a-1c6ba4eda704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "def dataPreprocessing_glove(data):\n",
        "    corpus = []\n",
        "    # Missing values\n",
        "    data[\"job\"].fillna(\"no-job\", inplace = True)\n",
        "    data[\"state\"].fillna(\"no-state\", inplace = True)\n",
        "\n",
        "    for x in range(data.shape[0]):\n",
        "        statement = re.sub('[^a-zA-Z]', ' ', data['statement'][x]) # Removing all numbers and special characters\n",
        "        statement = statement.lower() # Converting uppercase to lowercase\n",
        "        statement = word_tokenize(statement)\n",
        "\n",
        "        embed_statement = []\n",
        "        for w in statement:\n",
        "            if w in emmbed_dict:\n",
        "                embed_statement.append(emmbed_dict[w])\n",
        "            else:\n",
        "                embed_statement.append(emmbed_dict['oov'])\n",
        "         \n",
        "        # bonus: Think how you can encode the below features(hint: look upon label encoding or training your own word2vec or any other embedding model)\n",
        "    \n",
        "#         subject = data['subject'][x].replace(',', ' ')\n",
        "#         speaker = data['speaker'][x]\n",
        "#         job = data['job'][x].lower()\n",
        "#         # job = job.replace(' ', '-')\n",
        "#         state = data['state'][x].lower()\n",
        "#         party = data['party'][x].lower()\n",
        "        corpus.append(embed_statement)\n",
        "    \n",
        "    return np.array(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OkdqeQahzDb",
        "outputId": "7a14c4a2-c3bc-4608-87a9-c0abbc1c4f82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ],
      "source": [
        "x_train_glove = dataPreprocessing_glove(train)\n",
        "x_val_glove = dataPreprocessing_glove(val) \n",
        "x_test_glove = dataPreprocessing_glove(test) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "7Bk7Sj42hzDb"
      },
      "outputs": [],
      "source": [
        "x_train_glove = np.hstack((x_train_glove.reshape(-1,1), x_train2))\n",
        "x_val_glove = np.hstack((x_val_glove.reshape(-1,1), x_val2))\n",
        "x_test_glove = np.hstack((x_test_glove.reshape(-1,1), x_test2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz4Ic_SWhzDc"
      },
      "source": [
        "## Use of bert embeddings\n",
        "note: we used our pre-processed code for bow which has the attributed appended to end the end of sentence. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "S549_vruhzDc"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "x_train_bert = np.hstack((model.encode(x_train), x_train2))\n",
        "x_val_bert = np.hstack((model.encode(x_val), x_val2))\n",
        "x_test_bert = np.hstack((model.encode(x_test), x_test2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VD2BIMMhzDe"
      },
      "source": [
        "Now use the above 3 types of embedded inputs(bow, glove, bert embeddings) for the 2 classification tasks and compare their outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmavEzWHrTC8"
      },
      "source": [
        "# Six-way classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wAhr39Aq41J"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "yJwZwMXANg9_"
      },
      "outputs": [],
      "source": [
        "num_classes = 6\n",
        "# Preprocessing function for the labels\n",
        "def categorize(data):\n",
        "    y = data[\"label\"].tolist()\n",
        "\n",
        "    # Encoding the Dependent Variable\n",
        "    labelencoder_y = LabelEncoder()\n",
        "    y = labelencoder_y.fit_transform(y)\n",
        "\n",
        "    # Converting to binary class matrix\n",
        "    y = np_utils.to_categorical(y, num_classes)\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "XIKTUSM3MJ-u"
      },
      "outputs": [],
      "source": [
        "y_train_six_way = categorize(train)\n",
        "y_test_six_way = categorize(test)\n",
        "y_val_six_way = categorize(val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE_TGJPhhzDg"
      },
      "source": [
        "Build a model and pass bow, glove and bert embedded inputs: x_train_bow, x_train_glove, x_train_bert(similarly validate for val and report results on test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y-dusAUolnI"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Awnuxl89rVZB",
        "outputId": "e5d2655a-ee68-4611-a622-fc34fb22806e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10269, 8005)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "x_train_bow.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd24ZkVSNEcI",
        "outputId": "c53e4c50-e0f4-4c2a-97b4-f1a14c687e9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10269, 389)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "x_train_bert.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocMH35P3P_nL",
        "outputId": "41d10aa9-a0d4-46e2-941e-85e63d360e63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10269, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "x_train_glove.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_x_train_glove=np.zeros((10269,65,200))\n",
        "for i in range(x_train_glove.shape[0]):\n",
        "  num_array=np.array(x_train_glove[i][0])\n",
        "  final_x_train_glove[i,:num_array.shape[0],:]=num_array\n",
        "final_x_train_glove = final_x_train_glove.reshape(*final_x_train_glove.shape[:-2], -1)"
      ],
      "metadata": {
        "id": "MlMAnSaBjnaW"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_x_train_glove.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdzoWLCsjsgc",
        "outputId": "aabc4e4e-1d1b-4c82-b6e8-738427ad9a4c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10269, 13000)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlAK3g05Zlgx",
        "outputId": "270d7761-2614-4c09-d783-46d2b5e5ab12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1283, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "x_test_glove.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_x_test_glove=np.zeros((1283,65,200))\n",
        "for i in range(x_test_glove.shape[0]):\n",
        "  num_array=np.array(x_test_glove[i][0])\n",
        "  final_x_test_glove[i,:num_array.shape[0],:]=num_array\n",
        "final_x_test_glove = final_x_test_glove.reshape(*final_x_test_glove.shape[:-2], -1)"
      ],
      "metadata": {
        "id": "mpzMJ1LNjwHC"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_x_test_glove.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4Io--0aj7TJ",
        "outputId": "bd3105ca-2f43-4a2c-e35f-23448bf2695e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1283, 13000)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_val_glove.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5LMcjJYivpK",
        "outputId": "68e92e77-b8dd-4a09-9b55-acfb7ce0a51b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1284, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_x_val_glove=np.zeros((1284,65,200))\n",
        "for i in range(x_val_glove.shape[0]):\n",
        "  num_array=np.array(x_val_glove[i][0])\n",
        "  final_x_val_glove[i,:num_array.shape[0],:]=num_array\n",
        "final_x_val_glove = final_x_val_glove.reshape(*final_x_val_glove.shape[:-2], -1)"
      ],
      "metadata": {
        "id": "IzmWR3YKiZ7_"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_x_val_glove.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsBO_wPlhmEO",
        "outputId": "10749c1f-5733-464e-9633-9cce60540922"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1284, 13000)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_results(ypred,yactual):\n",
        "  ypred=np.argmax(ypred, axis=1)\n",
        "  yactual=np.argmax(yactual, axis=1)\n",
        "  mconfusion_mat = multilabel_confusion_matrix(yactual,ypred)\n",
        "  print(\"Confusion Matrix:\",mconfusion_mat)\n",
        "  f1score = f1_score(yactual, ypred,average=None)\n",
        "  print(\"F1_Score: \",f1score )"
      ],
      "metadata": {
        "id": "PkSthCmJTLQe"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWW2d9neI2v7",
        "outputId": "6a8bfda4-8804-4a36-b9f3-769b8dfc70a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "321/321 [==============================] - 41s 99ms/step - loss: 0.1353 - accuracy: 0.2423 - val_loss: 0.1319 - val_accuracy: 0.3045\n",
            "Epoch 2/10\n",
            "321/321 [==============================] - 29s 91ms/step - loss: 0.1258 - accuracy: 0.3521 - val_loss: 0.1198 - val_accuracy: 0.4042\n",
            "Epoch 3/10\n",
            "321/321 [==============================] - 29s 90ms/step - loss: 0.1092 - accuracy: 0.4406 - val_loss: 0.1062 - val_accuracy: 0.4579\n",
            "Epoch 4/10\n",
            "321/321 [==============================] - 29s 89ms/step - loss: 0.1061 - accuracy: 0.4542 - val_loss: 0.1049 - val_accuracy: 0.4626\n",
            "Epoch 5/10\n",
            "321/321 [==============================] - 28s 88ms/step - loss: 0.1052 - accuracy: 0.4528 - val_loss: 0.1042 - val_accuracy: 0.4556\n",
            "Epoch 6/10\n",
            "321/321 [==============================] - 28s 88ms/step - loss: 0.1049 - accuracy: 0.4528 - val_loss: 0.1044 - val_accuracy: 0.4556\n",
            "Epoch 7/10\n",
            "321/321 [==============================] - 28s 87ms/step - loss: 0.1046 - accuracy: 0.4565 - val_loss: 0.1046 - val_accuracy: 0.4556\n",
            "Epoch 8/10\n",
            "321/321 [==============================] - 28s 88ms/step - loss: 0.1043 - accuracy: 0.4566 - val_loss: 0.1038 - val_accuracy: 0.4611\n",
            "Epoch 9/10\n",
            "321/321 [==============================] - 28s 87ms/step - loss: 0.1043 - accuracy: 0.4578 - val_loss: 0.1040 - val_accuracy: 0.4517\n",
            "Epoch 10/10\n",
            "321/321 [==============================] - 28s 88ms/step - loss: 0.1040 - accuracy: 0.4591 - val_loss: 0.1043 - val_accuracy: 0.4634\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.1073 - accuracy: 0.4427\n",
            "Results For BERT\n",
            "Accuracy: 0.4427123963832855\n",
            "Confusion Matrix: [[[ 877  156]\n",
            "  [ 129  121]]\n",
            "\n",
            " [[1069    3]\n",
            "  [ 178   33]]\n",
            "\n",
            " [[ 995   74]\n",
            "  [ 133   81]]\n",
            "\n",
            " [[ 826  190]\n",
            "  [ 139  128]]\n",
            "\n",
            " [[ 772  262]\n",
            "  [  95  154]]\n",
            "\n",
            " [[1161   30]\n",
            "  [  41   51]]]\n",
            "F1_Score:  [0.45920304 0.26720648 0.43902439 0.43760684 0.46315789 0.58959538]\n"
          ]
        }
      ],
      "source": [
        "# BERT EMBEDDING\n",
        "model = Sequential()\n",
        "model.add(LSTM(100,input_shape=(389,1)))\n",
        "model.add(Dense(6,activation='softmax'))\n",
        "model.compile(loss='mse',optimizer ='adam',metrics=['accuracy'])\n",
        "model.fit(x_train_bert,y_train_six_way,epochs=10,validation_data=(x_val_bert,y_val_six_way),verbose=1)\n",
        "scores = model.evaluate(x_test_bert, y_test_six_way, batch_size=128)\n",
        "# loss, accuracy, f1_score, precision, recall\n",
        "print(\"Results For BERT\")\n",
        "print('Accuracy: {}'.format(scores[1]))\n",
        "y_pred = model.predict(x_test_bert)\n",
        "print_results(y_pred,y_test_six_way)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-k7_xSWQPqD",
        "outputId": "502a13cf-de21-48e3-d928-31e3fdfe5591"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "321/321 [==============================] - 7s 21ms/step - loss: 0.1570 - accuracy: 0.3473 - val_loss: 0.1442 - val_accuracy: 0.4167\n",
            "Epoch 2/10\n",
            "321/321 [==============================] - 7s 20ms/step - loss: 0.1258 - accuracy: 0.5086 - val_loss: 0.1536 - val_accuracy: 0.3988\n",
            "Epoch 3/10\n",
            "321/321 [==============================] - 7s 21ms/step - loss: 0.1132 - accuracy: 0.5819 - val_loss: 0.1534 - val_accuracy: 0.3793\n",
            "Epoch 4/10\n",
            "321/321 [==============================] - 7s 20ms/step - loss: 0.1065 - accuracy: 0.6270 - val_loss: 0.1665 - val_accuracy: 0.3917\n",
            "Epoch 5/10\n",
            "321/321 [==============================] - 7s 21ms/step - loss: 0.0992 - accuracy: 0.6644 - val_loss: 0.1860 - val_accuracy: 0.3637\n",
            "Epoch 6/10\n",
            "321/321 [==============================] - 7s 20ms/step - loss: 0.0978 - accuracy: 0.6784 - val_loss: 0.1860 - val_accuracy: 0.3715\n",
            "Epoch 7/10\n",
            "321/321 [==============================] - 7s 20ms/step - loss: 0.1021 - accuracy: 0.6689 - val_loss: 0.1868 - val_accuracy: 0.3692\n",
            "Epoch 8/10\n",
            "321/321 [==============================] - 7s 21ms/step - loss: 0.0991 - accuracy: 0.6806 - val_loss: 0.1814 - val_accuracy: 0.3785\n",
            "Epoch 9/10\n",
            "321/321 [==============================] - 7s 21ms/step - loss: 0.0950 - accuracy: 0.6951 - val_loss: 0.1808 - val_accuracy: 0.3902\n",
            "Epoch 10/10\n",
            "321/321 [==============================] - 7s 20ms/step - loss: 0.0987 - accuracy: 0.6885 - val_loss: 0.1952 - val_accuracy: 0.3474\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1953 - accuracy: 0.3352\n",
            "Results For BOW\n",
            "Accuracy : 0.3351520001888275\n",
            "Confusion Matrix: [[[ 713  320]\n",
            "  [ 128  122]]\n",
            "\n",
            " [[ 877  195]\n",
            "  [ 150   61]]\n",
            "\n",
            " [[ 946  123]\n",
            "  [ 144   70]]\n",
            "\n",
            " [[ 949   67]\n",
            "  [ 210   57]]\n",
            "\n",
            " [[ 929  105]\n",
            "  [ 171   78]]\n",
            "\n",
            " [[1148   43]\n",
            "  [  50   42]]]\n",
            "F1_Score:  [0.35260116 0.26124197 0.34398034 0.2915601  0.36111111 0.47457627]\n"
          ]
        }
      ],
      "source": [
        "# BOW EMBEDDING\n",
        "model = Sequential()\n",
        "model.add(Dense(5000,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(6,activation='softmax'))\n",
        "model.compile(loss='mse',optimizer ='adam',metrics=['accuracy'])\n",
        "model.fit(x_train_bow,y_train_six_way,epochs=10,validation_data=(x_val_bow,y_val_six_way),verbose=1)\n",
        "scores = model.evaluate(x_test_bow, y_test_six_way, batch_size=128)\n",
        "# loss, accuracy, f1_score, precision, recall\n",
        "print(\"Results For BOW\")\n",
        "print('Accuracy : {}'.format(scores[1]))\n",
        "y_pred = model.predict(x_test_bow)\n",
        "print_results(y_pred,y_test_six_way)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "kKQrJD_uQm3X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d092f1-5b3f-4102-a63a-ce86c5bab5d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "321/321 [==============================] - 13s 37ms/step - loss: 0.2791 - accuracy: 0.1609 - val_loss: 0.2718 - val_accuracy: 0.1846\n",
            "Epoch 2/10\n",
            "321/321 [==============================] - 12s 36ms/step - loss: 0.2795 - accuracy: 0.1614 - val_loss: 0.2718 - val_accuracy: 0.1846\n",
            "Epoch 3/10\n",
            "321/321 [==============================] - 11s 36ms/step - loss: 0.2795 - accuracy: 0.1614 - val_loss: 0.2718 - val_accuracy: 0.1846\n",
            "Epoch 4/10\n",
            "321/321 [==============================] - 12s 37ms/step - loss: 0.2795 - accuracy: 0.1614 - val_loss: 0.2718 - val_accuracy: 0.1846\n",
            "Epoch 5/10\n",
            "321/321 [==============================] - 13s 39ms/step - loss: 0.2795 - accuracy: 0.1614 - val_loss: 0.2718 - val_accuracy: 0.1846\n",
            "Epoch 6/10\n",
            "321/321 [==============================] - 13s 41ms/step - loss: 0.2795 - accuracy: 0.1614 - val_loss: 0.2718 - val_accuracy: 0.1846\n",
            "Epoch 7/10\n",
            "321/321 [==============================] - 12s 36ms/step - loss: 0.2795 - accuracy: 0.1614 - val_loss: 0.2718 - val_accuracy: 0.1846\n",
            "Epoch 8/10\n",
            "321/321 [==============================] - 11s 35ms/step - loss: 0.2795 - accuracy: 0.1614 - val_loss: 0.2718 - val_accuracy: 0.1846\n",
            "Epoch 9/10\n",
            "321/321 [==============================] - 11s 35ms/step - loss: 0.2795 - accuracy: 0.1614 - val_loss: 0.2718 - val_accuracy: 0.1846\n",
            "Epoch 10/10\n",
            "321/321 [==============================] - 11s 35ms/step - loss: 0.2795 - accuracy: 0.1614 - val_loss: 0.2718 - val_accuracy: 0.1846\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.2777 - accuracy: 0.1668\n",
            "Results For GLOVE\n",
            "Accuracy: 0.16679656505584717\n",
            "Confusion Matrix: [[[1033    0]\n",
            "  [ 250    0]]\n",
            "\n",
            " [[1072    0]\n",
            "  [ 211    0]]\n",
            "\n",
            " [[   0 1069]\n",
            "  [   0  214]]\n",
            "\n",
            " [[1016    0]\n",
            "  [ 267    0]]\n",
            "\n",
            " [[1034    0]\n",
            "  [ 249    0]]\n",
            "\n",
            " [[1191    0]\n",
            "  [  92    0]]]\n",
            "F1_Score:  [0.         0.         0.28590514 0.         0.         0.        ]\n"
          ]
        }
      ],
      "source": [
        "#GLOVE EMBEDDING\n",
        "model = Sequential()\n",
        "model.add(Dense(5000,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(2500,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(6,activation='softmax'))\n",
        "model.compile(loss='mse',optimizer ='adam',metrics=['accuracy'])\n",
        "model.fit(final_x_train_glove,y_train_six_way,epochs=10,validation_data=(final_x_val_glove,y_val_six_way),verbose=1)\n",
        "scores = model.evaluate(final_x_test_glove, y_test_six_way, batch_size=128)\n",
        "# loss, accuracy, f1_score, precision, recall\n",
        "print(\"Results For GLOVE\")\n",
        "print('Accuracy: {}'.format(scores[1]))\n",
        "y_pred = model.predict(final_x_test_glove)\n",
        "print_results(y_pred,y_test_six_way)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctoTOw2uIK1G"
      },
      "source": [
        "# Binary Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZJUrQ1SrEBa"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "eA3wQH1JinNx"
      },
      "outputs": [],
      "source": [
        "num_classes = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Mk-q1zwVF5KZ"
      },
      "outputs": [],
      "source": [
        "# Function for preprocessing labels\n",
        "def dataPreprocessingBinary(data):\n",
        "    y = data[\"label\"].tolist()\n",
        "\n",
        "    # Changing the 'half-true', 'mostly-true', barely-true', 'pants-fire' labels to True/False for Binary Classification\n",
        "    for x in range(len(y)):\n",
        "        if(y[x] == 'half-true'):\n",
        "            y[x] = 'True'\n",
        "        elif(y[x] == 'mostly-true'):\n",
        "            y[x] = 'True'\n",
        "        elif(y[x] == 'barely-true'):\n",
        "            y[x] = 'False'\n",
        "        elif(y[x] == 'pants-fire'):\n",
        "            y[x] = 'False'\n",
        "\n",
        "    # Converting the lables into binary class matrix\n",
        "    labelencoder_y = LabelEncoder()\n",
        "    y = labelencoder_y.fit_transform(y)\n",
        "    y = np_utils.to_categorical(y, num_classes)\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "REu1ue0xbuqp"
      },
      "outputs": [],
      "source": [
        "y_train_binary = dataPreprocessingBinary(train)\n",
        "y_test_binary = dataPreprocessingBinary(test)\n",
        "y_val_binary = dataPreprocessingBinary(val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI4PIrgR01Sd"
      },
      "source": [
        "## Model\n",
        "Build a model and pass bow, glove and bert embedded inputs: x_train_bow, x_train_glove, x_train_bert(similarly validate for val and report results on test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "-J0inPaQb-8Y"
      },
      "outputs": [],
      "source": [
        "## write your code here\n",
        "# Initialize hyperparameters\n",
        "# Create model\n",
        "# train\n",
        "# test\n",
        "# report accuracy, f1-score and confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYffCeEUQt7k",
        "outputId": "8ec12d5d-1b40-4fcc-ffb2-7d43359c7cbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "321/321 [==============================] - 32s 92ms/step - loss: 0.6511 - accuracy: 0.6200 - val_loss: 0.6227 - val_accuracy: 0.6612\n",
            "Epoch 2/10\n",
            "321/321 [==============================] - 29s 91ms/step - loss: 0.5696 - accuracy: 0.7045 - val_loss: 0.5686 - val_accuracy: 0.6869\n",
            "Epoch 3/10\n",
            "321/321 [==============================] - 28s 88ms/step - loss: 0.5416 - accuracy: 0.7106 - val_loss: 0.5317 - val_accuracy: 0.7079\n",
            "Epoch 4/10\n",
            "321/321 [==============================] - 28s 88ms/step - loss: 0.5263 - accuracy: 0.7181 - val_loss: 0.5244 - val_accuracy: 0.7017\n",
            "Epoch 5/10\n",
            "321/321 [==============================] - 28s 88ms/step - loss: 0.5192 - accuracy: 0.7248 - val_loss: 0.5171 - val_accuracy: 0.7033\n",
            "Epoch 6/10\n",
            "321/321 [==============================] - 28s 88ms/step - loss: 0.5121 - accuracy: 0.7295 - val_loss: 0.5155 - val_accuracy: 0.7118\n",
            "Epoch 7/10\n",
            "321/321 [==============================] - 28s 87ms/step - loss: 0.5086 - accuracy: 0.7305 - val_loss: 0.5145 - val_accuracy: 0.7048\n",
            "Epoch 8/10\n",
            "321/321 [==============================] - 28s 88ms/step - loss: 0.5051 - accuracy: 0.7284 - val_loss: 0.5062 - val_accuracy: 0.7150\n",
            "Epoch 9/10\n",
            "321/321 [==============================] - 28s 88ms/step - loss: 0.5029 - accuracy: 0.7281 - val_loss: 0.5036 - val_accuracy: 0.7142\n",
            "Epoch 10/10\n",
            "321/321 [==============================] - 28s 88ms/step - loss: 0.5005 - accuracy: 0.7320 - val_loss: 0.5091 - val_accuracy: 0.7087\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.5111 - accuracy: 0.7373\n",
            "Results For BERT\n",
            "Accuracy: 0.7373343706130981\n",
            "Confusion Matrix: [[[594 133]\n",
            "  [204 352]]\n",
            "\n",
            " [[352 204]\n",
            "  [133 594]]]\n",
            "F1_Score:  [0.67627281 0.77901639]\n"
          ]
        }
      ],
      "source": [
        "# BERT EMBEDDING\n",
        "model = Sequential()\n",
        "model.add(LSTM(100,input_shape=(389,1)))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.compile(loss='binary_crossentropy',optimizer ='adam',metrics=['accuracy'])\n",
        "model.fit(x_train_bert,y_train_binary,epochs=10,validation_data=(x_val_bert,y_val_binary),verbose=1)\n",
        "scores = model.evaluate(x_test_bert, y_test_binary, batch_size=128)\n",
        "print(\"Results For BERT\")\n",
        "print('Accuracy: {}'.format(scores[1]))\n",
        "y_pred = model.predict(x_test_bert)\n",
        "print_results(y_pred,y_test_binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "swvuB_dDXBkq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "836c49d2-27a8-43dc-dab6-7534b2919177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "321/321 [==============================] - 9s 26ms/step - loss: 0.9249 - accuracy: 0.6684 - val_loss: 0.5889 - val_accuracy: 0.6721\n",
            "Epoch 2/10\n",
            "321/321 [==============================] - 8s 26ms/step - loss: 0.5280 - accuracy: 0.7299 - val_loss: 0.5665 - val_accuracy: 0.7126\n",
            "Epoch 3/10\n",
            "321/321 [==============================] - 8s 26ms/step - loss: 0.4510 - accuracy: 0.7726 - val_loss: 0.5913 - val_accuracy: 0.6893\n",
            "Epoch 4/10\n",
            "321/321 [==============================] - 8s 26ms/step - loss: 0.3980 - accuracy: 0.8033 - val_loss: 0.6941 - val_accuracy: 0.6970\n",
            "Epoch 5/10\n",
            "321/321 [==============================] - 8s 26ms/step - loss: 0.3426 - accuracy: 0.8319 - val_loss: 0.8621 - val_accuracy: 0.6838\n",
            "Epoch 6/10\n",
            "321/321 [==============================] - 8s 26ms/step - loss: 0.3030 - accuracy: 0.8462 - val_loss: 0.9661 - val_accuracy: 0.6822\n",
            "Epoch 7/10\n",
            "321/321 [==============================] - 8s 26ms/step - loss: 0.2752 - accuracy: 0.8654 - val_loss: 1.1151 - val_accuracy: 0.6659\n",
            "Epoch 8/10\n",
            "321/321 [==============================] - 8s 26ms/step - loss: 0.2739 - accuracy: 0.8623 - val_loss: 1.0581 - val_accuracy: 0.6612\n",
            "Epoch 9/10\n",
            "321/321 [==============================] - 8s 26ms/step - loss: 0.2667 - accuracy: 0.8716 - val_loss: 1.1680 - val_accuracy: 0.6783\n",
            "Epoch 10/10\n",
            "321/321 [==============================] - 8s 26ms/step - loss: 0.2387 - accuracy: 0.8792 - val_loss: 1.3201 - val_accuracy: 0.6815\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 1.2797 - accuracy: 0.6625\n",
            "Results for BOW\n",
            "Accuracy for BOW EMBEDDING: 0.6625097393989563\n",
            "Confusion Matrix: [[[463 264]\n",
            "  [169 387]]\n",
            "\n",
            " [[387 169]\n",
            "  [264 463]]]\n",
            "F1_Score:  [0.64125932 0.68138337]\n"
          ]
        }
      ],
      "source": [
        "# BOW EMBEDDING\n",
        "model = Sequential()\n",
        "model.add(Dense(5000,activation='relu'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Dense(2000,activation='relu'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.compile(loss='binary_crossentropy',optimizer ='adam',metrics=['accuracy'])\n",
        "model.fit(x_train_bow,y_train_binary,epochs=10,validation_data=(x_val_bow,y_val_binary),verbose=1)\n",
        "scores = model.evaluate(x_test_bow, y_test_binary, batch_size=128)\n",
        "# loss, accuracy, f1_score, precision, recall\n",
        "print(\"Results for BOW\")\n",
        "print('Accuracy for BOW EMBEDDING: {}'.format(scores[1]))\n",
        "y_pred = model.predict(x_test_bow)\n",
        "print_results(y_pred,y_test_binary)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GLOVE EMBEDDING\n",
        "model = Sequential()\n",
        "model.add(Dense(5000,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(2500,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.compile(loss='binary_crossentropy',optimizer ='adam',metrics=['accuracy'])\n",
        "model.fit(final_x_train_glove,y_train_binary,epochs=10,validation_data=(final_x_val_glove,y_val_binary),verbose=1)\n",
        "scores = model.evaluate(final_x_test_glove, y_test_binary, batch_size=128)\n",
        "# loss, accuracy, f1_score, precision, recall\n",
        "print(\"Results For GLOVE\")\n",
        "print('Accuracy: {}'.format(scores[1]))\n",
        "y_pred = model.predict(final_x_test_glove)\n",
        "print_results(y_pred,y_test_binary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAfs-Mkldvl4",
        "outputId": "b2c18846-278f-485d-f02f-67bf42ce0f8a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "321/321 [==============================] - 12s 36ms/step - loss: 0.7015 - accuracy: 0.5769 - val_loss: 0.6809 - val_accuracy: 0.5335\n",
            "Epoch 2/10\n",
            "321/321 [==============================] - 12s 36ms/step - loss: 0.6274 - accuracy: 0.6533 - val_loss: 0.6655 - val_accuracy: 0.5880\n",
            "Epoch 3/10\n",
            "321/321 [==============================] - 12s 36ms/step - loss: 0.5220 - accuracy: 0.7446 - val_loss: 0.7270 - val_accuracy: 0.5911\n",
            "Epoch 4/10\n",
            "321/321 [==============================] - 11s 36ms/step - loss: 0.3267 - accuracy: 0.8617 - val_loss: 0.9770 - val_accuracy: 0.5849\n",
            "Epoch 5/10\n",
            "321/321 [==============================] - 11s 36ms/step - loss: 0.1470 - accuracy: 0.9422 - val_loss: 1.3607 - val_accuracy: 0.5833\n",
            "Epoch 6/10\n",
            "321/321 [==============================] - 12s 36ms/step - loss: 0.0970 - accuracy: 0.9633 - val_loss: 1.6143 - val_accuracy: 0.5732\n",
            "Epoch 7/10\n",
            "321/321 [==============================] - 11s 35ms/step - loss: 0.0658 - accuracy: 0.9772 - val_loss: 1.7396 - val_accuracy: 0.5888\n",
            "Epoch 8/10\n",
            "321/321 [==============================] - 12s 36ms/step - loss: 0.0601 - accuracy: 0.9792 - val_loss: 2.1307 - val_accuracy: 0.5826\n",
            "Epoch 9/10\n",
            "321/321 [==============================] - 11s 35ms/step - loss: 0.0500 - accuracy: 0.9832 - val_loss: 1.9470 - val_accuracy: 0.5771\n",
            "Epoch 10/10\n",
            "321/321 [==============================] - 11s 35ms/step - loss: 0.0477 - accuracy: 0.9851 - val_loss: 2.0488 - val_accuracy: 0.5841\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 2.0927 - accuracy: 0.5807\n",
            "Results For GLOVE\n",
            "Accuracy: 0.5806702971458435\n",
            "Confusion Matrix: [[[528 199]\n",
            "  [339 217]]\n",
            "\n",
            " [[217 339]\n",
            "  [199 528]]]\n",
            "F1_Score:  [0.44650206 0.66248432]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "2021201039_Assignment3_Q3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}